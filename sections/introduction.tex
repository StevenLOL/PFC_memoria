\section{Introduction}
\label{intro}
\thispagestyle{empty}

There are many different kind of speech synthesis systems, and all of them pursued the same goal: produce natural sounding speech, which is the main goal of speech synthesis. As an extra requirement to this main goal, TTS systems aim to create the speech from arbitrary texts given as inputs, increasing the difficulty. It is easy to assume that a considerably amount of data is needed in order to cover all the possible sounds combinations in a given text. Moreover, the current trend in TTS aims towards generating different speaking styles with different speaker characteristics and emotions expressed with our voice, enlarging the spectrum of the characteristics of the voice to take into account and its differences depending on the context, increasing the amount of data needed to develop the final system. 

It must be pointed out that among all the different techniques used nowadays to synthesize speech, some are not focused in maximum naturalness but they focus in intelligibility or high-speed synthesized speech. Although naturalness still a main issue, the final target, e.g. helping impaired people to navigate computers using a screen reader, forces to prioritize some other characteristics before naturalness. 

Among the synthesis techniques, when talking about fulfilling the general requirements presented so far: naturalness, speaker characteristics, emotions, style, etc., unit selection technique and Hidden Markov Model (HMM) approaches stand out. Although unit selection synthesis provides the greatest naturalness, it does not allow an easy adaptation of a TTS system to other speakers or speaking styles, requiring a large amount of data due to the selection and concatenation used in this kind of synthesis, making this technique not suitable for example to embedded systems. On the other hand, HMM-based systems make easier to use adaptation techniques and require less memory, making them very popular nowadays.

We can find various vocoders currently being used in HMM-based systems, but the Speech Transformation and Representation using Adaptive Interpolation of weiGHT spectrum (STRAIGHT) vocoder is the most commonly used and the most established one. However, due to the degradation in naturalness suffered in HMM-based systems, a new vocoder is being developed trying to solve this issue: the GlottHMM vocoder, which estimates a physically motivated model of the glottal signal and the vocal tract associated to it, producing a more natural voice. 

So far memory requirements and the amount of data needed to build the system have been pointed as some of the weak points in speech synthesis systems. The amount of data is particularly important in unit selection synthesis systems. Sadly, collecting data is not an easy task since speech synthesis systems need high quality recordings covering different contexts. Moreover, when using speaker-adaptive systems, where an average voice model is built from several speakers to adapt it later to a new target speaker, certain amount of audio recordings will be needed from a substantial number of speakers. Adapting an average voice model, made out from high quality recorded audio of different speakers, with non high quality recordings would facilitate the access to a bigger number of target voices.

Noisy conditions were explored in speech recognition systems before being tested in synthesis system. Speech recognition is highly related to statistically speech synthesis, specially HMM-based systems. For example, the analysis done to the audio recordings is the same in both cases, thus the same concepts used in recognition can be applied to speech synthesis systems. Nevertheless, speech recognition techniques under noisy conditions cannot satisfy all the needs of speech synthesis, so further research should be done in the future.

In this project the possibility of synthesizing speech from a model trained with noisy data will be explored. The aim is to adapt an average voice model made from high-quality training data, recorded in studio conditions, with noisy data, which is easier to obtain. HMM-based speech paradigm has been found to be quite robust on Mel-Cepstrum \cite{karhila_jstsp_14, yamagishi2008robustness} and Mel-LSP-based vocoders \cite{Yanagisawa_SSW8}, but different adaptation techniques, vocoding techniques and noise present in the adaptation data can reduce quality, naturalness and speaker similarity and also add some background noise to the synthesized speech compared to the adaptation made from clean data. 

A similar approach to this problem has been carried out in \cite{karhila_jstsp_14} using STRAIGHT vocoder. As GlottHMM targets on obtaining more natural voices, in this project we will study the effects of different types of noise present in adaptation data, using objective measures and subjective tests to evaluate the results. Besides, we will compare the performance made by GlottHMM vocoder with the one made by STRAIGHT vocoder in \cite{karhila_jstsp_14}, trying to established which conditions benefit each vocoder against the other and learn about the level of acceptance of the synthesized voices observed in the subjective tests. To make the comparison as fair as possible, we will be working in Finnish with the same training and adaptation data.
